{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_hw5_task3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM201hZIOflK5Al/1T2+Xfi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AALivanova/BI_Stat_2021/blob/ML_hw5/ML_hw5_task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import xgboost\n",
        "import lightgbm\n",
        "!pip install catboost\n",
        "import catboost\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "from scipy.stats import pearsonr\n",
        "from itertools import combinations\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import (RandomForestClassifier,\n",
        "                              ExtraTreesClassifier,\n",
        "                              VotingClassifier)\n",
        "from sklearn.tree import (DecisionTreeRegressor,\n",
        "                          DecisionTreeClassifier)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJynhZQAE6ZW",
        "outputId": "682c2558-a4ce-4d0a-afb8-17a9b41f2fb6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = 12, 9\n",
        "sns.set_style(\"whitegrid\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SEED = 111\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "OUtNBgBbFfTf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 3. Строим большой ансамбль\n",
        "4 балла + 3 дополнительных за эксперименты и максимально высокий скор\n",
        "\n",
        "В данной задаче вам нужно диагностировать сердечное заболевание у людей по медицинским показателям."
      ],
      "metadata": {
        "id": "m1lAgXpFEw4W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b4JG_DGoEP9U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "!gdown  --id 1VFbDK-Ad-hpf0_GGCBzn4thdn9mkQ-Y- -O heart.csv -q\n",
        "heart_dataset = pd.read_csv(\"heart.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heart_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "0XF1DaXpEZoI",
        "outputId": "453da3ca-9b15-4c21-b5d2-dedbf0ca41a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-46a6cd1d-90b4-4c81-b636-c1d7a2ac8e74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>241</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>110</td>\n",
              "      <td>264</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>193</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>115</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46a6cd1d-90b4-4c81-b636-c1d7a2ac8e74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46a6cd1d-90b4-4c81-b636-c1d7a2ac8e74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46a6cd1d-90b4-4c81-b636-c1d7a2ac8e74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "0     63    1   3       145   233    1        0      150      0      2.3   \n",
              "1     37    1   2       130   250    0        1      187      0      3.5   \n",
              "2     41    0   1       130   204    0        0      172      0      1.4   \n",
              "3     56    1   1       120   236    0        1      178      0      0.8   \n",
              "4     57    0   0       120   354    0        1      163      1      0.6   \n",
              "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
              "298   57    0   0       140   241    0        1      123      1      0.2   \n",
              "299   45    1   3       110   264    0        1      132      0      1.2   \n",
              "300   68    1   0       144   193    1        1      141      0      3.4   \n",
              "301   57    1   0       130   131    0        1      115      1      1.2   \n",
              "302   57    0   1       130   236    0        0      174      0      0.0   \n",
              "\n",
              "     slope  ca  thal  target  \n",
              "0        0   0     1       1  \n",
              "1        0   0     2       1  \n",
              "2        2   0     2       1  \n",
              "3        2   0     2       1  \n",
              "4        2   0     2       1  \n",
              "..     ...  ..   ...     ...  \n",
              "298      1   0     3       0  \n",
              "299      1   0     3       0  \n",
              "300      1   2     3       0  \n",
              "301      1   1     3       0  \n",
              "302      1   1     2       0  \n",
              "\n",
              "[303 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = heart_dataset.drop(\"target\", axis=1)\n",
        "y = heart_dataset[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=SEED)\n",
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6TjXzxukErIG",
        "outputId": "f7783e37-0e74-4ebc-9e24-8025dc045c8e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-257622c0-716c-4dcf-a88b-91a9385db693\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>177</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>241</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>134</td>\n",
              "      <td>409</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>146</td>\n",
              "      <td>278</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-257622c0-716c-4dcf-a88b-91a9385db693')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-257622c0-716c-4dcf-a88b-91a9385db693 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-257622c0-716c-4dcf-a88b-91a9385db693');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "178   43    1   0       120   177    0        0      120      1      2.5   \n",
              "298   57    0   0       140   241    0        1      123      1      0.2   \n",
              "201   60    1   0       125   258    0        0      141      1      2.8   \n",
              "246   56    0   0       134   409    0        0      150      1      1.9   \n",
              "153   66    0   2       146   278    0        0      152      0      0.0   \n",
              "\n",
              "     slope  ca  thal  \n",
              "178      1   0     3  \n",
              "298      1   0     3  \n",
              "201      1   1     3  \n",
              "246      1   2     3  \n",
              "153      1   1     2  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучите разнообразные классификаторы, приведенные ниже, а также ансамбль VotingClassifier из sklearn.ensemble, объединяющий эти классификаторы с помощью жесткого или мякого голосования (параметр voting = 'hard' или 'soft' соответственно). Оцените качество моделей с помощью кросс-валидации на тренировочном наборе, используя функцию cross_val_score и метрику f1. Часть моделей отсюда мы не проходили, о них можно почитать дополнительно, но в принципе для задания не очень важно знать принципы их работы (но, если есть время, то почитайте, там интересно)."
      ],
      "metadata": {
        "id": "3PUSx0DVFmWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(random_state=SEED, max_depth=10, min_samples_leaf=10)\n",
        "rf = RandomForestClassifier(n_estimators=50, random_state=SEED)\n",
        "etc = ExtraTreesClassifier(random_state=SEED)\n",
        "knn = KNeighborsClassifier(n_neighbors=5, weights=\"distance\")\n",
        "svc_lin = SVC(kernel='linear', probability=True, random_state=SEED)\n",
        "svc_rbf = SVC(kernel='rbf', probability=True, random_state=SEED)\n",
        "cat = catboost.CatBoostClassifier(verbose=0, random_seed=SEED)\n",
        "lgbm = lightgbm.LGBMClassifier(random_state=SEED)\n",
        "lgbm_rf = lightgbm.LGBMClassifier(boosting_type=\"rf\", bagging_freq=1, bagging_fraction=0.7, random_state=SEED)\n",
        "xgb = xgboost.XGBClassifier(random_state=SEED)\n",
        "xgb_rf = xgboost.XGBRFClassifier(random_state=SEED)\n",
        "lr = LogisticRegression(solver='liblinear', max_iter=10000)\n",
        "nb = GaussianNB()\n",
        "\n",
        "base_models = [(\"DT\", dt), (\"RF\", rf), \n",
        "               (\"ETC\", etc), (\"KNN\", knn), \n",
        "               (\"SVC_LIN\", svc_lin), (\"SVC_RBF\", svc_rbf), \n",
        "               (\"CAT\", cat), (\"LGBM\", lgbm), \n",
        "               (\"LGBM_RF\", lgbm_rf), (\"XGB\", xgb), \n",
        "               (\"XGB_RF\", xgb_rf), (\"LR\", lr), (\"NB\", nb)]"
      ],
      "metadata": {
        "id": "PkHyu_jvFnKR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_hard = VotingClassifier(estimators= base_models, voting='hard')\n",
        "\n",
        "voting_soft = VotingClassifier(estimators=base_models, voting='soft')"
      ],
      "metadata": {
        "id": "Sjb0oL1WE16m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in [dt, rf, cat, etc, knn, svc_lin, svc_rbf, xgb, lgbm, xgb_rf, lgbm_rf, lr, nb, voting_hard, voting_soft]: \n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\")\n",
        "    print(f\"{model.__class__.__name__}: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7lQv8_NFq1G",
        "outputId": "7b161843-0414-4ff7-d785-9fd9b3199529"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier: 0.797997226792219\n",
            "RandomForestClassifier: 0.8328751280279528\n",
            "CatBoostClassifier: 0.8342715174922052\n",
            "ExtraTreesClassifier: 0.828174603174603\n",
            "KNeighborsClassifier: 0.6493313763861709\n",
            "SVC: 0.8403098469098905\n",
            "SVC: 0.6973119072190279\n",
            "XGBClassifier: 0.8380318868123746\n",
            "LGBMClassifier: 0.8129461544095692\n",
            "XGBRFClassifier: 0.8488204901143478\n",
            "LGBMClassifier: 0.8101597492003888\n",
            "LogisticRegression: 0.8500073681108163\n",
            "GaussianNB: 0.8140676625250128\n",
            "VotingClassifier: 0.8490813069126322\n",
            "VotingClassifier: 0.8583484026522002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вы можете заметить, что ансамбль показывает хорошее, но не лучшее качество предсказания, попробуем его улучшить. Как вы знаете, ансамбли работают лучше, когда модели, входящие в них не скоррелированы друг с другом. Определите корреляцию предсказаний базовых моделей в ансамбле на тестовом наборе данных, и удалите из ансамбля те модели, чьи предсказания будут сильнее коррелировать с остальными. Воспользуйтесь функцией base_model_pair_correlation_for_voting_clf. Спойлер: далеко не факт, что если вы удалите две модели с корреляцией 0.95, то все станет сильно лучше, здесь все будет немного сложнее. Чтобы добиться максимального качества может понадобиться долгий перебор различных комбинаций моделей. Наилучший скор, который мне удалось достичь, это 0.915, но он получен весьма странной комбинацией алгоритмов, а еще и простым перебором всех вариантов)"
      ],
      "metadata": {
        "id": "kFkQ3vScFzYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def base_model_pair_correlation_for_voting_clf(ensemble, X):\n",
        "    corrs = []\n",
        "    base_model_names = [f\"{est.__class__.__name__}\" for est in ensemble.estimators_]\n",
        "    for (i, est1), (j, est2) in combinations(enumerate(ensemble.estimators_), 2):\n",
        "        Xi_test = X\n",
        "        Xj_test = X\n",
        "\n",
        "        if not isinstance(est1, SVC):\n",
        "            ypred_t1 = est1.predict_proba(Xi_test)[:, 1]\n",
        "        else:\n",
        "            ypred_t1 = est1.decision_function(Xi_test)\n",
        "\n",
        "\n",
        "        if not isinstance(est2, SVC):\n",
        "            ypred_t2 = est2.predict_proba(Xi_test)[:, 1]\n",
        "        else:\n",
        "            ypred_t2 = est2.decision_function(Xi_test)\n",
        "        corrs.append((est1, est2, pearsonr(ypred_t1, ypred_t2)[0]))\n",
        "\n",
        "\n",
        "    return corrs"
      ],
      "metadata": {
        "id": "IuVeQBqFFtHn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_soft.fit(X_train, y_train)\n",
        "base_model_pair_correlation_for_voting_clf(voting_soft, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo0MGn7-F1l-",
        "outputId": "6d979ba3-e29b-494e-dd81-f264f7e73a1e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  0.8134894007824364),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  ExtraTreesClassifier(random_state=111),\n",
              "  0.7749544834941163),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  KNeighborsClassifier(weights='distance'),\n",
              "  0.31332949662835446),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  SVC(kernel='linear', probability=True, random_state=111),\n",
              "  0.715376472596946),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  SVC(probability=True, random_state=111),\n",
              "  0.2820135356695378),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  <catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  0.7875690140798687),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  LGBMClassifier(random_state=111),\n",
              "  0.8294070001470021),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  0.8530144286862672),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  XGBClassifier(random_state=111),\n",
              "  0.8313145089263169),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  XGBRFClassifier(random_state=111),\n",
              "  0.9064903955507417),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.7399817403132603),\n",
              " (DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, random_state=111),\n",
              "  GaussianNB(),\n",
              "  0.6827714012201818),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  ExtraTreesClassifier(random_state=111),\n",
              "  0.9215651183028867),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  KNeighborsClassifier(weights='distance'),\n",
              "  0.3924167426564557),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  SVC(kernel='linear', probability=True, random_state=111),\n",
              "  0.8263983680718642),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  SVC(probability=True, random_state=111),\n",
              "  0.4055273375196602),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  <catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  0.9450698035153566),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  LGBMClassifier(random_state=111),\n",
              "  0.9072815640080156),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  0.9233539716879783),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  XGBClassifier(random_state=111),\n",
              "  0.9276101950095837),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  XGBRFClassifier(random_state=111),\n",
              "  0.9385353102545836),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.8377708628482852),\n",
              " (RandomForestClassifier(n_estimators=50, random_state=111),\n",
              "  GaussianNB(),\n",
              "  0.7988431534180455),\n",
              " (ExtraTreesClassifier(random_state=111),\n",
              "  KNeighborsClassifier(weights='distance'),\n",
              "  0.322398286410264),\n",
              " (ExtraTreesClassifier(random_state=111),\n",
              "  SVC(kernel='linear', probability=True, random_state=111),\n",
              "  0.887752826126888),\n",
              " (ExtraTreesClassifier(random_state=111),\n",
              "  SVC(probability=True, random_state=111),\n",
              "  0.35885458306081897),\n",
              " (ExtraTreesClassifier(random_state=111),\n",
              "  <catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  0.9527199736215165),\n",
              " (ExtraTreesClassifier(random_state=111),\n",
              "  LGBMClassifier(random_state=111),\n",
              "  0.8766407455315567),\n",
              " (ExtraTreesClassifier(random_state=111),\n",
              "  LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  0.875022642429207),\n",
              " (ExtraTreesClassifier(random_state=111),\n",
              "  XGBClassifier(random_state=111),\n",
              "  0.8844597300590482),\n",
              " (ExtraTreesClassifier(random_state=111),\n",
              "  XGBRFClassifier(random_state=111),\n",
              "  0.9006756099278739),\n",
              " (ExtraTreesClassifier(random_state=111),\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.8693492910343703),\n",
              " (ExtraTreesClassifier(random_state=111), GaussianNB(), 0.8522994111599133),\n",
              " (KNeighborsClassifier(weights='distance'),\n",
              "  SVC(kernel='linear', probability=True, random_state=111),\n",
              "  0.2497903579278884),\n",
              " (KNeighborsClassifier(weights='distance'),\n",
              "  SVC(probability=True, random_state=111),\n",
              "  0.5659803075895896),\n",
              " (KNeighborsClassifier(weights='distance'),\n",
              "  <catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  0.31720692942108),\n",
              " (KNeighborsClassifier(weights='distance'),\n",
              "  LGBMClassifier(random_state=111),\n",
              "  0.2954574430399729),\n",
              " (KNeighborsClassifier(weights='distance'),\n",
              "  LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  0.40694670120428167),\n",
              " (KNeighborsClassifier(weights='distance'),\n",
              "  XGBClassifier(random_state=111),\n",
              "  0.34342858857530784),\n",
              " (KNeighborsClassifier(weights='distance'),\n",
              "  XGBRFClassifier(random_state=111),\n",
              "  0.38610098294237766),\n",
              " (KNeighborsClassifier(weights='distance'),\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.2697340600205871),\n",
              " (KNeighborsClassifier(weights='distance'), GaussianNB(), 0.23137181767934303),\n",
              " (SVC(kernel='linear', probability=True, random_state=111),\n",
              "  SVC(probability=True, random_state=111),\n",
              "  0.33397170567092727),\n",
              " (SVC(kernel='linear', probability=True, random_state=111),\n",
              "  <catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  0.8627983793864165),\n",
              " (SVC(kernel='linear', probability=True, random_state=111),\n",
              "  LGBMClassifier(random_state=111),\n",
              "  0.8176946412421725),\n",
              " (SVC(kernel='linear', probability=True, random_state=111),\n",
              "  LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  0.805263661122052),\n",
              " (SVC(kernel='linear', probability=True, random_state=111),\n",
              "  XGBClassifier(random_state=111),\n",
              "  0.8126802267177068),\n",
              " (SVC(kernel='linear', probability=True, random_state=111),\n",
              "  XGBRFClassifier(random_state=111),\n",
              "  0.8180632931076239),\n",
              " (SVC(kernel='linear', probability=True, random_state=111),\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.9521587816734959),\n",
              " (SVC(kernel='linear', probability=True, random_state=111),\n",
              "  GaussianNB(),\n",
              "  0.8325613230185709),\n",
              " (SVC(probability=True, random_state=111),\n",
              "  <catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  0.31065818680334994),\n",
              " (SVC(probability=True, random_state=111),\n",
              "  LGBMClassifier(random_state=111),\n",
              "  0.21282355886649185),\n",
              " (SVC(probability=True, random_state=111),\n",
              "  LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  0.3871532735212278),\n",
              " (SVC(probability=True, random_state=111),\n",
              "  XGBClassifier(random_state=111),\n",
              "  0.29122476374029643),\n",
              " (SVC(probability=True, random_state=111),\n",
              "  XGBRFClassifier(random_state=111),\n",
              "  0.3520088472351744),\n",
              " (SVC(probability=True, random_state=111),\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.4016749832017506),\n",
              " (SVC(probability=True, random_state=111), GaussianNB(), 0.4223350936090538),\n",
              " (<catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  LGBMClassifier(random_state=111),\n",
              "  0.9464480518845135),\n",
              " (<catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  0.8949311753753943),\n",
              " (<catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  XGBClassifier(random_state=111),\n",
              "  0.9610843452511352),\n",
              " (<catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  XGBRFClassifier(random_state=111),\n",
              "  0.9227830526280457),\n",
              " (<catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.870647099750969),\n",
              " (<catboost.core.CatBoostClassifier at 0x7f5367ea3110>,\n",
              "  GaussianNB(),\n",
              "  0.8246563436068889),\n",
              " (LGBMClassifier(random_state=111),\n",
              "  LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  0.8649616849316482),\n",
              " (LGBMClassifier(random_state=111),\n",
              "  XGBClassifier(random_state=111),\n",
              "  0.9693894697337859),\n",
              " (LGBMClassifier(random_state=111),\n",
              "  XGBRFClassifier(random_state=111),\n",
              "  0.9044413027803704),\n",
              " (LGBMClassifier(random_state=111),\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.8323653974127515),\n",
              " (LGBMClassifier(random_state=111), GaussianNB(), 0.740848331552273),\n",
              " (LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  XGBClassifier(random_state=111),\n",
              "  0.8886647827120704),\n",
              " (LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  XGBRFClassifier(random_state=111),\n",
              "  0.9764638672015389),\n",
              " (LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111),\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.7997831039595935),\n",
              " (LGBMClassifier(bagging_fraction=0.7, bagging_freq=1, boosting_type='rf',\n",
              "                 random_state=111), GaussianNB(), 0.7542263532834699),\n",
              " (XGBClassifier(random_state=111),\n",
              "  XGBRFClassifier(random_state=111),\n",
              "  0.9338208992617397),\n",
              " (XGBClassifier(random_state=111),\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.8227950841621414),\n",
              " (XGBClassifier(random_state=111), GaussianNB(), 0.7314999332139198),\n",
              " (XGBRFClassifier(random_state=111),\n",
              "  LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  0.8132195815725107),\n",
              " (XGBRFClassifier(random_state=111), GaussianNB(), 0.759038382809811),\n",
              " (LogisticRegression(max_iter=10000, solver='liblinear'),\n",
              "  GaussianNB(),\n",
              "  0.8925145264153072)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "как будто бы надо удалить cat и XGB, пробуем"
      ],
      "metadata": {
        "id": "CRRBNM2EJoWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [(\"DT\", dt), (\"RF\", rf), \n",
        "               (\"ETC\", etc), (\"KNN\", knn), \n",
        "               (\"SVC_LIN\", svc_lin), (\"SVC_RBF\", svc_rbf), \n",
        "               (\"LGBM\", lgbm), \n",
        "               (\"LGBM_RF\", lgbm_rf),  \n",
        "               (\"XGB_RF\", xgb_rf), (\"LR\", lr), (\"NB\", nb)]\n",
        "\n",
        "voting_hard = VotingClassifier(estimators= base_models, voting='hard')\n",
        "voting_soft = VotingClassifier(estimators=base_models, voting='soft')\n",
        "\n",
        "for model in [voting_hard, voting_soft]: \n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\")\n",
        "    print(f\"{model.__class__.__name__}: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32pPhE77GKUG",
        "outputId": "4935b296-dafa-4e1a-86f7-d0a0b603033d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VotingClassifier: 0.8450142450142449\n",
            "VotingClassifier: 0.8535431660336342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "но ничего не поменялось особо, а стало даже хуже, пробуем другие комбинации\n",
        "Пробую удалять один классификатор из ансамбля"
      ],
      "metadata": {
        "id": "QWlUD7ONJunE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(0,13):\n",
        "  base_models = [(\"DT\", dt), (\"RF\", rf), \n",
        "               (\"ETC\", etc), (\"KNN\", knn), \n",
        "               (\"SVC_LIN\", svc_lin), (\"SVC_RBF\", svc_rbf), \n",
        "               (\"CAT\", cat), (\"LGBM\", lgbm), \n",
        "               (\"LGBM_RF\", lgbm_rf), (\"XGB\", xgb), \n",
        "               (\"XGB_RF\", xgb_rf), (\"LR\", lr), (\"NB\", nb)]\n",
        "  base_models.pop(i)\n",
        "  voting_hard = VotingClassifier(estimators= base_models, voting='hard')\n",
        "  voting_soft = VotingClassifier(estimators=base_models, voting='soft')\n",
        "\n",
        "  for model in [voting_hard, voting_soft]: \n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\")\n",
        "    print(i)\n",
        "    print(f\"{model.__class__.__name__}: {scores.mean()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lF5siZbNtMZ",
        "outputId": "cf353e25-7349-48c6-9a33-2049fb3984b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "VotingClassifier: 0.8431938431938434\n",
            "0\n",
            "VotingClassifier: 0.8533870490762153\n",
            "1\n",
            "VotingClassifier: 0.851356032357316\n",
            "1\n",
            "VotingClassifier: 0.8583484026522002\n",
            "2\n",
            "VotingClassifier: 0.8440863019176272\n",
            "2\n",
            "VotingClassifier: 0.863016936732499\n",
            "3\n",
            "VotingClassifier: 0.8527443105756358\n",
            "3\n",
            "VotingClassifier: 0.8551737994775969\n",
            "4\n",
            "VotingClassifier: 0.8431938431938434\n",
            "4\n",
            "VotingClassifier: 0.8534798534798534\n",
            "5\n",
            "VotingClassifier: 0.8527443105756358\n",
            "5\n",
            "VotingClassifier: 0.8583484026522002\n",
            "6\n",
            "VotingClassifier: 0.8481888481888481\n",
            "6\n",
            "VotingClassifier: 0.8583484026522002\n",
            "7\n",
            "VotingClassifier: 0.8527055600226333\n",
            "7\n",
            "VotingClassifier: 0.84856642687968\n",
            "8\n",
            "VotingClassifier: 0.8395804737268152\n",
            "8\n",
            "VotingClassifier: 0.8583484026522002\n",
            "9\n",
            "VotingClassifier: 0.8518518518518517\n",
            "9\n",
            "VotingClassifier: 0.8535431660336342\n",
            "10\n",
            "VotingClassifier: 0.8468393205235311\n",
            "10\n",
            "VotingClassifier: 0.853949856084979\n",
            "11\n",
            "VotingClassifier: 0.8432259510565032\n",
            "11\n",
            "VotingClassifier: 0.8583484026522002\n",
            "12\n",
            "VotingClassifier: 0.8527443105756358\n",
            "12\n",
            "VotingClassifier: 0.8594304388422035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "как будто бы эффективно удалять ETC, удалим и попробуем снова поудалять еще один случайный классификатор"
      ],
      "metadata": {
        "id": "1mRmx2TKTBH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,12):\n",
        "  base_models = [(\"DT\", dt), (\"RF\", rf), \n",
        "                (\"KNN\", knn), \n",
        "               (\"SVC_LIN\", svc_lin), (\"SVC_RBF\", svc_rbf), \n",
        "               (\"CAT\", cat), (\"LGBM\", lgbm), \n",
        "               (\"LGBM_RF\", lgbm_rf), (\"XGB\", xgb), \n",
        "               (\"XGB_RF\", xgb_rf), (\"LR\", lr), (\"NB\", nb)]\n",
        "  base_models_pop = base_models.pop(i)\n",
        "  voting_hard = VotingClassifier(estimators= base_models, voting='hard')\n",
        "  voting_soft = VotingClassifier(estimators=base_models, voting='soft')\n",
        "\n",
        "  for model in [voting_hard, voting_soft]: \n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\")\n",
        "    print(i)\n",
        "    print(f\"{model.__class__.__name__}: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNbgfs_ZPnk8",
        "outputId": "a74f1546-31d8-48ae-9a16-bc4014851b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "VotingClassifier: 0.848754835997926\n",
            "0\n",
            "VotingClassifier: 0.8541613425334357\n",
            "1\n",
            "VotingClassifier: 0.863016936732499\n",
            "1\n",
            "VotingClassifier: 0.863016936732499\n",
            "2\n",
            "VotingClassifier: 0.8550958684827493\n",
            "2\n",
            "VotingClassifier: 0.8583484026522002\n",
            "3\n",
            "VotingClassifier: 0.848754835997926\n",
            "3\n",
            "VotingClassifier: 0.863016936732499\n",
            "4\n",
            "VotingClassifier: 0.853949856084979\n",
            "4\n",
            "VotingClassifier: 0.8583484026522002\n",
            "5\n",
            "VotingClassifier: 0.8630952380952381\n",
            "5\n",
            "VotingClassifier: 0.863016936732499\n",
            "6\n",
            "VotingClassifier: 0.8499095840867993\n",
            "6\n",
            "VotingClassifier: 0.8464285714285715\n",
            "7\n",
            "VotingClassifier: 0.854578118167098\n",
            "7\n",
            "VotingClassifier: 0.863016936732499\n",
            "8\n",
            "VotingClassifier: 0.8490813069126322\n",
            "8\n",
            "VotingClassifier: 0.8547619047619047\n",
            "9\n",
            "VotingClassifier: 0.854578118167098\n",
            "9\n",
            "VotingClassifier: 0.863016936732499\n",
            "10\n",
            "VotingClassifier: 0.8499095840867993\n",
            "10\n",
            "VotingClassifier: 0.8547619047619047\n",
            "11\n",
            "VotingClassifier: 0.8597644025630481\n",
            "11\n",
            "VotingClassifier: 0.8594304388422035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "как будто бы полезно удалить классификатор с индексом 1"
      ],
      "metadata": {
        "id": "eeUrCCM7Ts5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,11):\n",
        "  base_models = [(\"DT\", dt),  \n",
        "                (\"KNN\", knn), \n",
        "               (\"SVC_LIN\", svc_lin), (\"SVC_RBF\", svc_rbf), \n",
        "               (\"CAT\", cat), (\"LGBM\", lgbm), \n",
        "               (\"LGBM_RF\", lgbm_rf), (\"XGB\", xgb), \n",
        "               (\"XGB_RF\", xgb_rf), (\"LR\", lr), (\"NB\", nb)]\n",
        "  base_models_pop = base_models.pop(i)\n",
        "  voting_hard = VotingClassifier(estimators= base_models, voting='hard')\n",
        "  voting_soft = VotingClassifier(estimators=base_models, voting='soft')\n",
        "\n",
        "  for model in [voting_hard, voting_soft]: \n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\")\n",
        "    print(i)\n",
        "    print(f\"{model.__class__.__name__}: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjBE613ITKwi",
        "outputId": "c5af7fa8-2075-4ff0-b736-03a1ab7cc556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "VotingClassifier: 0.8514242958687402\n",
            "0\n",
            "VotingClassifier: 0.8591380816873899\n",
            "1\n",
            "VotingClassifier: 0.856368563685637\n",
            "1\n",
            "VotingClassifier: 0.8551737994775969\n",
            "2\n",
            "VotingClassifier: 0.8425841025327546\n",
            "2\n",
            "VotingClassifier: 0.863016936732499\n",
            "3\n",
            "VotingClassifier: 0.856368563685637\n",
            "3\n",
            "VotingClassifier: 0.8583484026522002\n",
            "4\n",
            "VotingClassifier: 0.861981984599035\n",
            "4\n",
            "VotingClassifier: 0.8675769002527908\n",
            "5\n",
            "VotingClassifier: 0.8558406363284412\n",
            "5\n",
            "VotingClassifier: 0.8535431660336342\n",
            "6\n",
            "VotingClassifier: 0.8531533825651474\n",
            "6\n",
            "VotingClassifier: 0.8675769002527908\n",
            "7\n",
            "VotingClassifier: 0.8502887443210136\n",
            "7\n",
            "VotingClassifier: 0.8583954867087398\n",
            "8\n",
            "VotingClassifier: 0.8594861136581292\n",
            "8\n",
            "VotingClassifier: 0.863016936732499\n",
            "9\n",
            "VotingClassifier: 0.8473492969371219\n",
            "9\n",
            "VotingClassifier: 0.863016936732499\n",
            "10\n",
            "VotingClassifier: 0.8527443105756358\n",
            "10\n",
            "VotingClassifier: 0.8594304388422035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "удалим 4"
      ],
      "metadata": {
        "id": "2CSAw9jLUKsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,10):\n",
        "  base_models = [(\"DT\", dt),  \n",
        "                (\"KNN\", knn), \n",
        "               (\"SVC_LIN\", svc_lin), (\"SVC_RBF\", svc_rbf), \n",
        "               (\"LGBM\", lgbm), \n",
        "               (\"LGBM_RF\", lgbm_rf), (\"XGB\", xgb), \n",
        "               (\"XGB_RF\", xgb_rf), (\"LR\", lr), (\"NB\", nb)]\n",
        "  base_models_pop = base_models.pop(i)\n",
        "  voting_hard = VotingClassifier(estimators= base_models, voting='hard')\n",
        "  voting_soft = VotingClassifier(estimators=base_models, voting='soft')\n",
        "\n",
        "  for model in [voting_hard, voting_soft]: \n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\")\n",
        "    print(i)\n",
        "    print(f\"{model.__class__.__name__}: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hbnk5ARTr1C",
        "outputId": "e074d97a-8020-4b31-f2ae-6fe28eeb297c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "VotingClassifier: 0.8634585442151296\n",
            "0\n",
            "VotingClassifier: 0.8547395351201686\n",
            "1\n",
            "VotingClassifier: 0.8599206349206349\n",
            "1\n",
            "VotingClassifier: 0.8515873015873016\n",
            "2\n",
            "VotingClassifier: 0.8666505186793337\n",
            "2\n",
            "VotingClassifier: 0.863016936732499\n",
            "3\n",
            "VotingClassifier: 0.8599206349206349\n",
            "3\n",
            "VotingClassifier: 0.8598249622682946\n",
            "4\n",
            "VotingClassifier: 0.8604534416736715\n",
            "4\n",
            "VotingClassifier: 0.851538712991501\n",
            "5\n",
            "VotingClassifier: 0.8598249622682946\n",
            "5\n",
            "VotingClassifier: 0.8675769002527908\n",
            "6\n",
            "VotingClassifier: 0.8604534416736715\n",
            "6\n",
            "VotingClassifier: 0.8630640207890385\n",
            "7\n",
            "VotingClassifier: 0.8634585442151296\n",
            "7\n",
            "VotingClassifier: 0.8631783536855696\n",
            "8\n",
            "VotingClassifier: 0.8551737994775969\n",
            "8\n",
            "VotingClassifier: 0.863016936732499\n",
            "9\n",
            "VotingClassifier: 0.8677637721755369\n",
            "9\n",
            "VotingClassifier: 0.8594304388422035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "удалим 5"
      ],
      "metadata": {
        "id": "8y3PsrnjUcbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,9):\n",
        "  base_models = [(\"DT\", dt),  \n",
        "                (\"KNN\", knn), \n",
        "               (\"SVC_LIN\", svc_lin), (\"SVC_RBF\", svc_rbf), \n",
        "               (\"LGBM\", lgbm), \n",
        "                (\"XGB\", xgb), \n",
        "               (\"XGB_RF\", xgb_rf), (\"LR\", lr), (\"NB\", nb)]\n",
        "  base_models_pop = base_models.pop(i)\n",
        "  voting_hard = VotingClassifier(estimators= base_models, voting='hard')\n",
        "  voting_soft = VotingClassifier(estimators=base_models, voting='soft')\n",
        "\n",
        "  for model in [voting_hard, voting_soft]: \n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\")\n",
        "    print(i)\n",
        "    print(f\"{model.__class__.__name__}: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRm_VE59UJ76",
        "outputId": "ff1b3ff7-99b2-4e8a-c4ae-b23b272fce79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "VotingClassifier: 0.8491871146437228\n",
            "0\n",
            "VotingClassifier: 0.8595918557952742\n",
            "1\n",
            "VotingClassifier: 0.8484848484848486\n",
            "1\n",
            "VotingClassifier: 0.8598249622682946\n",
            "2\n",
            "VotingClassifier: 0.8560245664376148\n",
            "2\n",
            "VotingClassifier: 0.8631783536855696\n",
            "3\n",
            "VotingClassifier: 0.8571428571428571\n",
            "3\n",
            "VotingClassifier: 0.8675769002527908\n",
            "4\n",
            "VotingClassifier: 0.8539388322520852\n",
            "4\n",
            "VotingClassifier: 0.854578118167098\n",
            "5\n",
            "VotingClassifier: 0.844535951853025\n",
            "5\n",
            "VotingClassifier: 0.8639904023624955\n",
            "6\n",
            "VotingClassifier: 0.8476863931430012\n",
            "6\n",
            "VotingClassifier: 0.8631783536855696\n",
            "7\n",
            "VotingClassifier: 0.8527443105756358\n",
            "7\n",
            "VotingClassifier: 0.8631783536855696\n",
            "8\n",
            "VotingClassifier: 0.8618113912231559\n",
            "8\n",
            "VotingClassifier: 0.8594304388422035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,8):\n",
        "  base_models = [(\"DT\", dt),  \n",
        "                (\"KNN\", knn), \n",
        "               (\"SVC_LIN\", svc_lin),  \n",
        "               (\"LGBM\", lgbm), \n",
        "                (\"XGB\", xgb), \n",
        "               (\"XGB_RF\", xgb_rf), (\"LR\", lr), (\"NB\", nb)]\n",
        "  base_models_pop = base_models.pop(i)\n",
        "  voting_hard = VotingClassifier(estimators= base_models, voting='hard')\n",
        "  voting_soft = VotingClassifier(estimators=base_models, voting='soft')\n",
        "\n",
        "  for model in [voting_hard, voting_soft]: \n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\")\n",
        "    print(i)\n",
        "    print(f\"{model.__class__.__name__}: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZn_3WPDUpHO",
        "outputId": "86f82b9f-b57d-4bec-c392-a71431b77c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "VotingClassifier: 0.8595006526041008\n",
            "0\n",
            "VotingClassifier: 0.8547395351201686\n",
            "1\n",
            "VotingClassifier: 0.8551737994775969\n",
            "1\n",
            "VotingClassifier: 0.8551737994775969\n",
            "2\n",
            "VotingClassifier: 0.8666953961071607\n",
            "2\n",
            "VotingClassifier: 0.8675769002527908\n",
            "3\n",
            "VotingClassifier: 0.8614532019704434\n",
            "3\n",
            "VotingClassifier: 0.8518399178107781\n",
            "4\n",
            "VotingClassifier: 0.8567063665274054\n",
            "4\n",
            "VotingClassifier: 0.8518399178107781\n",
            "5\n",
            "VotingClassifier: 0.8631636562671045\n",
            "5\n",
            "VotingClassifier: 0.8631783536855696\n",
            "6\n",
            "VotingClassifier: 0.8588522588522588\n",
            "6\n",
            "VotingClassifier: 0.8598249622682946\n",
            "7\n",
            "VotingClassifier: 0.8714557552978999\n",
            "7\n",
            "VotingClassifier: 0.8594304388422035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,6):\n",
        "  base_models = [(\"DT\", dt),  \n",
        "                (\"KNN\", knn), \n",
        "  \n",
        "                \n",
        "                (\"XGB\", xgb), \n",
        "               (\"XGB_RF\", xgb_rf), (\"LR\", lr)]\n",
        "  base_models_pop = base_models.pop(i)\n",
        "  voting_hard = VotingClassifier(estimators= base_models, voting='hard')\n",
        "  voting_soft = VotingClassifier(estimators=base_models, voting='soft')\n",
        "\n",
        "  for model in [voting_hard, voting_soft]: \n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\")\n",
        "    print(i)\n",
        "    print(f\"{model.__class__.__name__}: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct6OyMyrUsNT",
        "outputId": "3037f344-034b-4cad-ba79-f72b9e60fa8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "VotingClassifier: 0.8691160372194854\n",
            "0\n",
            "VotingClassifier: 0.8639904023624955\n",
            "1\n",
            "VotingClassifier: 0.8594944150499707\n",
            "1\n",
            "VotingClassifier: 0.8451285552093847\n",
            "2\n",
            "VotingClassifier: 0.874723729154109\n",
            "2\n",
            "VotingClassifier: 0.8455110375195781\n",
            "3\n",
            "VotingClassifier: 0.8614532019704434\n",
            "3\n",
            "VotingClassifier: 0.852740521991168\n",
            "4\n",
            "VotingClassifier: 0.8691160372194854\n",
            "4\n",
            "VotingClassifier: 0.8607827038861521\n",
            "5\n",
            "VotingClassifier: 0.8630952380952381\n",
            "5\n",
            "VotingClassifier: 0.8455110375195781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Короче говоря, таким нехитрым образом я перебирала варианты, пока не нашла лучшее сочетание"
      ],
      "metadata": {
        "id": "QIExqgxmXy5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [(\"DT\", dt),  \n",
        "                (\"KNN\", knn), \n",
        "  \n",
        "                \n",
        "                (\"XGB\", xgb), \n",
        "               (\"XGB_RF\", xgb_rf), (\"LR\", lr)]\n",
        "\n",
        "voting_hard = VotingClassifier(estimators= base_models, voting='hard')\n",
        "voting_soft = VotingClassifier(estimators=base_models, voting='soft')\n",
        "\n",
        "for model in [voting_hard, voting_soft]: \n",
        "  scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\")\n",
        "  print(f\"{model.__class__.__name__}: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDbGh-82VAWb",
        "outputId": "80837cb2-2858-48af-8d5b-de154824a2c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VotingClassifier: 0.874723729154109\n",
            "VotingClassifier: 0.8455110375195781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно посчитать f1 скор на тесте таким сочетанием классификаторов в ансамбле"
      ],
      "metadata": {
        "id": "kFNjBjtEPR3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "voting_hard.fit(X_train, y_train)\n",
        "\n",
        "y_pred = voting_hard.predict(X_test)\n",
        "f1_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoA89Gl7LL73",
        "outputId": "0a5f6ae7-f14a-4f50-8ad4-2457f5cb5263"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8910891089108911"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}